{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пайплайн принимает в себя методы выбора, обработки данных, модель обучения и последовательно выполняет каждое действие. При этом он перенимает все методы модели.\n",
    "\n",
    "В узком смысле пайплайн – это модуль sklearn.pipeline, который позволяет автоматизировать предварительные преобразования данных перед обучением модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт пайплайна\n",
    "from sklearn.pipeline import Pipeline, make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт классов для дополнительных преобразований\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример 1. Pipeline для векторного представления текста с TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>class</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Need Ethernet access</td>\n",
       "      <td>Please connect the LAN cable to the red port o...</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Create new account and share the username and ...</td>\n",
       "      <td>Go to URL : accountsetup.com, Enter personal d...</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FW: Myspace Login Issue-- Ania</td>\n",
       "      <td>Go to URL : password.reset.com, Enter you logi...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                               Need Ethernet access   \n",
       "1  Create new account and share the username and ...   \n",
       "2                     FW: Myspace Login Issue-- Ania   \n",
       "\n",
       "                                          Resolution  class  category  \n",
       "0  Please connect the LAN cable to the red port o...     41         1  \n",
       "1  Go to URL : accountsetup.com, Enter personal d...     35         0  \n",
       "2  Go to URL : password.reset.com, Enter you logi...     36         0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"support_data.csv\").drop('Unnamed: 0', 1)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут ради демонстрации Pipeline и tfidf возьмем признак Title и обработаем его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем tfidf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#разделим данные на train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, df['category'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соберем простой пайплайн. Для этого напишем класс, который будет выбирать признак\n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        return X[self.column]\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pipeline = Pipeline([('title_selector', FeatureSelector(column='Title')), # выбираем данные признака Title\n",
    "                     ('tfidf', TfidfVectorizer()), # трансформируем их в вектора\n",
    "                     ('classificator', LogisticRegression())], verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .... (step 1 of 3) Processing title_selector, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ..... (step 3 of 3) Processing classificator, total=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('title_selector', FeatureSelector(column='Title')),\n",
       "                ('tfidf', TfidfVectorizer()),\n",
       "                ('classificator', LogisticRegression())],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучим пайплайн\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91081012, 0.08918988],\n",
       "       [0.92431379, 0.07568621],\n",
       "       [0.76492273, 0.23507727],\n",
       "       [0.83646514, 0.16353486],\n",
       "       [0.76874921, 0.23125079],\n",
       "       [0.91265265, 0.08734735],\n",
       "       [0.9098258 , 0.0901742 ],\n",
       "       [0.91546489, 0.08453511],\n",
       "       [0.71695714, 0.28304286],\n",
       "       [0.90211255, 0.09788745]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict_proba(X_test)[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipeline.predict_proba(X_test)[:,1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.214648, F-Score=0.960, Precision=0.923, Recall=1.000\n"
     ]
    }
   ],
   "source": [
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как это интерпретировать?\n",
    "\n",
    "Допустим, что у нас в тесте 1000 заявок. Из них класс 1 - 200\n",
    "\n",
    "Мы обучили модель, сделали прогноз, посчитали порог и выше этого порога у нас 100 заявок.\n",
    "\n",
    "При этом оказывается, что среди этих 100 заявок - 80 действительно класс 1.\n",
    "\n",
    "TP = 80, FP = 20, TN = 780, FN = 120\n",
    "\n",
    "Precision = TP/(TP+FP) = 80/(80+20) = 0.8\n",
    "\n",
    "Recall = TP/(TP+FN) = 80/(80+120) = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример 2. Поочередное применение пайплайнов до модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_case2.csv', ';')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сразу разделим нашим данные на трейн и тест\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('cardio',1), df['cardio'], test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем несколько классов для выбора и обработки данных, но сначала нам нужно понять, что делать\n",
    "\n",
    "К полям:\n",
    "- gender, cholesterol применим OHE-кодирование(это dummies)\n",
    "- age, height, weight, ap_hi, ap_lo - StandardScaler\n",
    "- gluc, smoke, alco, active - оставим пока как есть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Трансформатор для выбора одного столбца из фрейма данных для выполнения дополнительных преобразований \n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "# Выбор значений числового признака\n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "# Dummies кодирование\n",
    "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.get_dummies(X, prefix=self.key)\n",
    "        test_columns = [col for col in X.columns]\n",
    "        for col_ in test_columns:\n",
    "            if col_ not in self.columns:\n",
    "                X[col_] = 0\n",
    "        return X[self.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отсортируем наши признаки для разных пайплайнов\n",
    "continuos_cols = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
    "cat_cols = ['gender', 'cholesterol']\n",
    "base_cols = ['gluc', 'smoke', 'alco', 'active']\n",
    "# Пустые списки для трансформированных данных\n",
    "continuos_transformers = []\n",
    "cat_transformers = []\n",
    "base_transformers = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь запустим нашу обработку, в рамках которой и соберем пайплайны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cont_col in continuos_cols:\n",
    "    # создаем объект класса Pipeline\n",
    "    transfomer =  Pipeline([\n",
    "        # вызываем класс выбора признака для значений признака cont_col\n",
    "                ('selector', NumberSelector(key=cont_col)),\n",
    "        # применяем стандартизацию для выбранного признака\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "    continuos_transformers.append((cont_col, transfomer))\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "for cat_col in cat_cols:\n",
    "    # создаем объект класса Pipeline\n",
    "    cat_transformer = Pipeline([\n",
    "        # вызываем класс выбора признаков из cat_col\n",
    "                ('selector', ColumnSelector(key=cat_col)),\n",
    "        # преобразуем их в dummies переменные\n",
    "                ('ohe', OHEEncoder(key=cat_col))\n",
    "            ])\n",
    "    cat_transformers.append((cat_col, cat_transformer))\n",
    "    \n",
    "    \n",
    "for base_col in base_cols:\n",
    "    # создаем объекст класса Pipeline\n",
    "    base_transformer = Pipeline([\n",
    "        ('selector', NumberSelector(key = base_col)),\n",
    "    ])\n",
    "    base_transformers.append((base_col, base_transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age',\n",
       "  Pipeline(steps=[('selector', NumberSelector(key='age')),\n",
       "                  ('standard', StandardScaler())])),\n",
       " ('height',\n",
       "  Pipeline(steps=[('selector', NumberSelector(key='height')),\n",
       "                  ('standard', StandardScaler())])),\n",
       " ('weight',\n",
       "  Pipeline(steps=[('selector', NumberSelector(key='weight')),\n",
       "                  ('standard', StandardScaler())])),\n",
       " ('ap_hi',\n",
       "  Pipeline(steps=[('selector', NumberSelector(key='ap_hi')),\n",
       "                  ('standard', StandardScaler())])),\n",
       " ('ap_lo',\n",
       "  Pipeline(steps=[('selector', NumberSelector(key='ap_lo')),\n",
       "                  ('standard', StandardScaler())]))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# На выходе имеем список кортежей ('признак', Pipeline обработки)\n",
    "continuos_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь необходимо объединить наши трансформеры в единое целое\n",
    "\n",
    "В этом нам поможет FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureUnion(transformer_list=[('age',\n",
       "                                Pipeline(steps=[('selector',\n",
       "                                                 NumberSelector(key='age')),\n",
       "                                                ('standard',\n",
       "                                                 StandardScaler())])),\n",
       "                               ('height',\n",
       "                                Pipeline(steps=[('selector',\n",
       "                                                 NumberSelector(key='height')),\n",
       "                                                ('standard',\n",
       "                                                 StandardScaler())])),\n",
       "                               ('weight',\n",
       "                                Pipeline(steps=[('selector',\n",
       "                                                 NumberSelector(key='weight')),\n",
       "                                                ('standard',\n",
       "                                                 StandardScaler())])),\n",
       "                               ('ap_hi',\n",
       "                                Pipeline(step...\n",
       "                                                 ColumnSelector(key='cholesterol')),\n",
       "                                                ('ohe',\n",
       "                                                 OHEEncoder(key='cholesterol'))])),\n",
       "                               ('gluc',\n",
       "                                Pipeline(steps=[('selector',\n",
       "                                                 NumberSelector(key='gluc'))])),\n",
       "                               ('smoke',\n",
       "                                Pipeline(steps=[('selector',\n",
       "                                                 NumberSelector(key='smoke'))])),\n",
       "                               ('alco',\n",
       "                                Pipeline(steps=[('selector',\n",
       "                                                 NumberSelector(key='alco'))])),\n",
       "                               ('active',\n",
       "                                Pipeline(steps=[('selector',\n",
       "                                                 NumberSelector(key='active'))]))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# объединим все трансформеры\n",
    "feats = FeatureUnion(continuos_transformers+cat_transformers+base_transformers)\n",
    "feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И запихнем все это в единый пайплайн\n",
    "Тут в пайплайн в виде метода уже передается созданный список FeatureUnion, состоящий из нескольких Pipeline's с уже определенными нами методами для каждого признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feats',\n",
       "                 FeatureUnion(transformer_list=[('age',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='age')),\n",
       "                                                                 ('standard',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('height',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='height')),\n",
       "                                                                 ('standard',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('weight',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='weight')),\n",
       "                                                                 ('standard',\n",
       "                                                                  StandardScaler())]...\n",
       "                                                                  ColumnSelector(key='cholesterol')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEEncoder(key='cholesterol'))])),\n",
       "                                                ('gluc',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='gluc'))])),\n",
       "                                                ('smoke',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='smoke'))])),\n",
       "                                                ('alco',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='alco'))])),\n",
       "                                                ('active',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='active'))]))]))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_processing = Pipeline([('feats', feats)])\n",
    "feature_processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Натренируем общий пайплайн( тоесть проведем обработку, вызвав метод fit_transform для X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38817489, -0.5308834 , -0.70816849, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 1.30846829,  0.32314728, -0.63861364, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.34652706, -0.5308834 , -0.56905879, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 1.67245587,  0.56715605, -0.01261999, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.49851342,  0.32314728, -0.29083939, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.75890645,  1.54319112, -0.70816849, ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_processing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавим классификатор в наш пайплайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Pipeline([('features', feats),\n",
    "                      ('classifier', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запустим кросс-валидацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score равен 0.7800680715650671 с std 0.008891911952969385\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(classifier, X_train, y_train, cv = 16, scoring='roc_auc')\n",
    "cv_score = np.mean(cv_scores)\n",
    "cv_score_std = np.std(cv_scores)\n",
    "print('CV score равен {} с std {}'.format(cv_score, cv_score_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель на всем тренировочном сете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train)\n",
    "y_score = classifier.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем precision,recall и trashold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший trashold 0.4101026847780329  f_score  0.7343882213572517  precision  0.6626708406505306  recall  0.8235126672359806\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "# найдем точность, полноту и порог\n",
    "precision, recall, threshold = precision_recall_curve(y_test.values, y_score)\n",
    "# посчитаем f_score без дизбаланса точности/полноты\n",
    "b = 1\n",
    "fscore = (1+b**2)*(precision * recall)/(b**2*precision + recall)\n",
    "# возьмем индексы самого большого значения f_score. Они же буду отвечать оптимальным значения в precision, recall и trashold\n",
    "ix = np.argmax(fscore)\n",
    "print('Лучший threshold {}  f_score  {}  precision  {}  recall  {}'.format(threshold[ix], fscore[ix], precision[ix], recall[ix]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
